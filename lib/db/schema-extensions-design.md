# AI Schema Extensions Design

## Overview
This document outlines the database schema extensions needed to support comprehensive AI pipeline infrastructure for the EHR system.

## New Tables Design

### 1. Treatment Plan Tables

```sql
-- treatment_plan: Stores overall treatment plans for patients
treatment_plan {
  id: uuid (PK)
  patient_id: uuid (FK -> patient.id)
  provider_id: uuid (FK -> provider.id)
  title: varchar(255)
  description: text
  status: varchar(50) -- 'active', 'completed', 'paused', 'cancelled'
  start_date: timestamp
  end_date: timestamp (nullable)
  created_at: timestamp
  updated_at: timestamp
}

-- treatment_goal: Individual goals within a treatment plan
treatment_goal {
  id: uuid (PK)
  treatment_plan_id: uuid (FK -> treatment_plan.id)
  goal_text: text
  target_date: timestamp (nullable)
  status: varchar(50) -- 'not_started', 'in_progress', 'achieved', 'modified', 'discontinued'
  progress_percentage: integer (0-100)
  priority: integer -- 1 (highest) to 5 (lowest)
  created_at: timestamp
  updated_at: timestamp
  achieved_at: timestamp (nullable)
}
```

### 2. Clinical Data Tables

```sql
-- diagnosis: Patient diagnoses with ICD-10 codes
diagnosis {
  id: uuid (PK)
  patient_id: uuid (FK -> patient.id)
  provider_id: uuid (FK -> provider.id)
  session_id: uuid (FK -> session.id, nullable) -- Link to session where diagnosed
  icd10_code: varchar(10)
  description: text
  status: varchar(50) -- 'active', 'resolved', 'in_remission'
  onset_date: timestamp (nullable)
  resolved_date: timestamp (nullable)
  created_at: timestamp
  updated_at: timestamp
}

-- medication: Patient medications
medication {
  id: uuid (PK)
  patient_id: uuid (FK -> patient.id)
  provider_id: uuid (FK -> provider.id)
  medication_name: varchar(255)
  dosage: varchar(100)
  frequency: varchar(100)
  route: varchar(50) -- 'oral', 'injection', 'topical', etc.
  start_date: timestamp
  end_date: timestamp (nullable)
  status: varchar(50) -- 'active', 'discontinued', 'completed'
  notes: text (nullable)
  created_at: timestamp
  updated_at: timestamp
}
```

### 3. Assessment Tables

```sql
-- assessment: Standardized assessments (PHQ-9, GAD-7, etc.)
assessment {
  id: uuid (PK)
  patient_id: uuid (FK -> patient.id)
  provider_id: uuid (FK -> provider.id)
  session_id: uuid (FK -> session.id, nullable)
  assessment_type: varchar(50) -- 'PHQ-9', 'GAD-7', 'PCL-5', 'AUDIT', etc.
  total_score: integer
  severity: varchar(50) -- Calculated based on type and score
  responses: jsonb -- Array of question/answer pairs
  administered_at: timestamp
  created_at: timestamp
}

-- Example JSONB structure for responses:
{
  "questions": [
    {
      "question_id": 1,
      "question_text": "Little interest or pleasure in doing things",
      "response_value": 2,
      "response_text": "More than half the days"
    },
    // ... more questions
  ]
}
```

### 4. AI Pipeline Audit Table

```sql
-- ai_pipeline_execution: Comprehensive audit trail for all AI operations
ai_pipeline_execution {
  id: uuid (PK)
  pipeline_type: varchar(100) -- 'safety_check', 'billing_automation', 'progress_tracking', etc.
  session_id: uuid (FK -> session.id, nullable)
  patient_id: uuid (FK -> patient.id, nullable)
  user_id: uuid (FK -> user.id) -- Who triggered the pipeline
  
  -- Input/Output tracking
  input_data: jsonb -- Full input context
  output_data: jsonb -- AI response/results
  
  -- Performance metrics
  start_time: timestamp
  end_time: timestamp
  duration_ms: integer
  
  -- Token usage (for cost tracking)
  input_tokens: integer
  output_tokens: integer
  total_tokens: integer
  model_used: varchar(100)
  
  -- Status tracking
  status: varchar(50) -- 'started', 'completed', 'failed', 'cancelled'
  error_message: text (nullable)
  
  -- Caching
  cache_hit: boolean default false
  cache_key: varchar(255) (nullable)
  
  created_at: timestamp
}
```

### 5. Supporting Tables

```sql
-- alert: Safety alerts generated by AI
alert {
  id: uuid (PK)
  patient_id: uuid (FK -> patient.id)
  provider_id: uuid (FK -> provider.id)
  session_id: uuid (FK -> session.id, nullable)
  pipeline_execution_id: uuid (FK -> ai_pipeline_execution.id)
  
  alert_type: varchar(100) -- 'suicide_risk', 'violence_risk', 'substance_abuse', etc.
  severity: varchar(20) -- 'low', 'medium', 'high', 'critical'
  risk_score: decimal(3,2) -- 0.00 to 1.00
  
  alert_title: varchar(255)
  alert_description: text
  recommended_actions: jsonb -- Array of recommended actions
  
  status: varchar(50) -- 'new', 'acknowledged', 'resolved', 'false_positive'
  acknowledged_by: uuid (FK -> user.id, nullable)
  acknowledged_at: timestamp (nullable)
  
  created_at: timestamp
  updated_at: timestamp
}

-- billing_suggestion: AI-generated billing codes
billing_suggestion {
  id: uuid (PK)
  session_id: uuid (FK -> session.id)
  pipeline_execution_id: uuid (FK -> ai_pipeline_execution.id)
  
  cpt_codes: jsonb -- Array of {code, description, confidence}
  icd10_codes: jsonb -- Array of {code, description, confidence}
  modifiers: jsonb -- Array of billing modifiers
  
  documentation_complete: boolean
  missing_elements: jsonb -- Array of missing documentation
  
  status: varchar(50) -- 'pending', 'approved', 'modified', 'rejected'
  reviewed_by: uuid (FK -> user.id, nullable)
  reviewed_at: timestamp (nullable)
  
  created_at: timestamp
}
```

## Schema Implementation Notes

### Data Types
- All primary keys use UUID for consistency
- Timestamps include timezone information
- JSONB used for flexible, queryable structured data
- VARCHAR lengths chosen based on standard requirements

### Indexes (to be added)
- Foreign key indexes on all reference columns
- Composite indexes for common query patterns:
  - `(patient_id, created_at)` on most tables
  - `(pipeline_type, created_at)` on ai_pipeline_execution
  - `(alert_type, severity, status)` on alert table

### Constraints
- Proper foreign key constraints with CASCADE options
- CHECK constraints for enums (status fields, etc.)
- NOT NULL constraints on required fields
- Unique constraints where applicable

### Migration Strategy
During development:
1. Add new table definitions to `schema.ts`
2. Run `npm run db:push` to recreate database
3. Test with sample data
4. Iterate as needed

Production migration files will be created once schema is stable.

## Next Steps
1. Implement these tables in `lib/db/schema.ts`
2. Create corresponding TypeScript types
3. Add query functions in `lib/db/queries.ts`
4. Test with sample data
5. Build services that utilize these tables
